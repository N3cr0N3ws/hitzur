<!DOCTYPE html>
<html lang="es">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="theme-color" content="#ffffff">
  
    <!-- SEO Optimized Meta Tags -->
    <title>Un estudio revela que Facebook podría tumbar el impacto viral de los bulos</title>
    <link rel="canonical" href="https://www.hitzur.com/pages/un-estudio-revela-que-facebook-podra-tumbar-el-impacto-viral-de-los-bulos.html" />
    <meta name="description" content=""La propagación de desinformación en redes sociales ha sido un desafío constante, especialmente durante eventos electorales. En 2020, Facebook implementó medidas estrictas que limitaron la viralidad de contenidos falsos, pero en 2024, la empresa optó por no aplicar las mismas restricciones, lo que generó preocupaciones sobre su compromiso en combatir la desinformación.">
    
    <meta name="Author" content="Maïder">
    <meta name="robots" content="INDEX, FOLLOW">
    <meta name="lang" content="es">

    <!-- Open Graph Tags -->
    <meta property="og:title" content="Un estudio revela que Facebook podría tumbar el impacto viral de los bulos">
    <meta property="og:description" content="La propagación de desinformación en redes sociales ha sido un desafío constante, especialmente durante eventos electorales. En 2020, Facebook implementó medidas estrictas que limitaron la viralidad de contenidos falsos, pero en 2024, la empresa optó por no aplicar las mismas restricciones, lo que generó preocupaciones sobre su compromiso en combatir la desinformación.">
    <meta property="og:site_name" content="hitzur">
    <meta property="og:locale" content="es_ES">
    <meta property="og:image" content="https://imagenes.elpais.com/resizer/v2/F4P7JIDQMJE6JIJ325LLT6MRUM.jpg?auth=488cdeae7cc4bfab44e7362ecdcb7928a7482eaced21af5c762ce2ed62cc0f67&width=1200">
    <meta property="og:url" content="https://www.hitzur.com/pages/un-estudio-revela-que-facebook-podra-tumbar-el-impacto-viral-de-los-bulos.html">

   <!-- Amplitude -->
    <script src="https://cdn.amplitude.com/libs/analytics-browser-2.11.1-min.js.gz"></script>
    <script src="https://cdn.amplitude.com/libs/plugin-session-replay-browser-1.8.0-min.js.gz"></script>
    <script>
        // Generar un UUID para identificar al usuario
        function generateUUID() {
            return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
                var r = Math.random() * 16 | 0, v = c === 'x' ? r : (r & 0x3 | 0x8);
                return v.toString(16);
            });
        }

        // Recuperar el User ID del localStorage, o generar uno si no existe
        let userId = localStorage.getItem('amplitude_user_id');
        if (!userId) {
            userId = generateUUID();
            localStorage.setItem('amplitude_user_id', userId);
        }

        // Configurar Amplitude con el User ID
        window.amplitude.setUserId(userId);
        window.amplitude.add(window.sessionReplay.plugin({sampleRate: 1}));
        window.amplitude.init('318a32d4d18e51e6f30e99db76b4226d', {
            serverZone: "EU",
            autocapture: {
                elementInteractions: true
            }
        });

        // (Opcional) Registrar un evento de prueba
        window.amplitude.track("Page Loaded", {
            page: window.location.pathname,
            referrer: document.referrer
        });
    </script>

    <!-- Page js -->
    <script src="/assets/js/avatars.js"></script>
    <script src="/assets/js/main.js"></script>
    
    <!-- non rotate -->
    <meta http-equiv="ScreenOrientation" content="autoRotate:disabled">
    
    <!-- css -->
    <link rel="stylesheet" type="text/css" href="../css/principal.css" />

    <!-- fonts -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&family=Montserrat:wght@400;700&display=swap">
</head>
<body>
  <div class="container">
    <div class="news-card" style="background: url('https://imagenes.elpais.com/resizer/v2/F4P7JIDQMJE6JIJ325LLT6MRUM.jpg?auth=488cdeae7cc4bfab44e7362ecdcb7928a7482eaced21af5c762ce2ed62cc0f67&width=1200') center/cover no-repeat;">
      <div class="layer"></div>
      <div class="text-overlay ">
        <span class="emotional">Esperanza digital</span>
        <h1>Un estudio revela que Facebook podría tumbar el impacto viral de los bulos</h1>
        <span class="publish-date">Publicada el 12/12/2024</span>
        <p class="resume">Un estudio ha demostrado que cambios en las políticas de moderación de Facebook durante las elecciones estadounidenses de 2020 redujeron casi a cero las visualizaciones de desinformación. Sin embargo, en 2024, la plataforma no implementó medidas similares, lo que sugiere que la efectividad en controlar la propagación de bulos depende de decisiones internas de la compañía.</p>
      </div>
    </div>
    <div class="context">
      <div class="explain">
        <span><strong>Análisis y contexto adicional</strong><br />Información relevante no incluida en la noticia original, pero clave para entender el tema a fondo.</span>
      </div>
      
      <!-- Context -->
      <h2>Contexto</h2>
      <p>La propagación de desinformación en redes sociales ha sido un desafío constante, especialmente durante eventos electorales. En 2020, Facebook implementó medidas estrictas que limitaron la viralidad de contenidos falsos, pero en 2024, la empresa optó por no aplicar las mismas restricciones, lo que generó preocupaciones sobre su compromiso en combatir la desinformación.</p>

      <!-- Who is who -->
      
      
      <h2>Quién es Quién</h2>
      <div class="who"> 
        <div class="card-container">
          
          <div class="who-card">
            <h3>Mark Zuckerberg</h3>
            <p><em>Presidente ejecutivo de Meta, la empresa matriz de Facebook.</em></p>
          </div>
          
          <div class="who-card">
            <h3>Nick Clegg</h3>
            <p><em>Presidente de Asuntos Globales de Meta, responsable de comunicar las políticas de la empresa.</em></p>
          </div>
          
          <div class="who-card">
            <h3>David Lazer</h3>
            <p><em>Profesor de la Universidad Northeastern de Boston y coautor del estudio sobre la moderación de desinformación en Facebook.</em></p>
          </div>
          
        </div>
      </div>
      

      <!-- Timeline hits -->
      
      
      <h2>Linea de tiempo</h2>
      <ul class="timeline">
        
        <li class="timeline-item">
          <div class="timeline-date">3 de diciembre de 2024</div>
          <p class="timeline-description">
            Nick Clegg, presidente de Asuntos Globales de Meta, declara que la empresa ha aprendido de errores pasados en la aplicación de sus reglas de moderación.
          </p>
        </li>
        
        <li class="timeline-item">
          <div class="timeline-date">12 de diciembre de 2024</div>
          <p class="timeline-description">
            Se publica un estudio que revela la capacidad de Facebook para reducir la viralidad de bulos mediante cambios en sus políticas de moderación.
          </p>
        </li>
        
      </ul>
      

      <!-- Next steps -->
      
      
      <ul class="steps">
        <li class="steps-item">
          <div class="steps-tittle">Futuro posible</div>
          <p class="steps-description">
            Se anticipa que Meta evaluará sus políticas de moderación a la luz de estos hallazgos y considerará la implementación de medidas más proactivas para combatir la desinformación en futuros eventos críticos. Además, es probable que se intensifiquen los debates regulatorios sobre la responsabilidad de las plataformas en la difusión de contenido falso.
          </p>
        </li>
      </ul>
      
      
      <!-- Glossary terms -->
      
      
      <h2>Glosario de Términos</h2>
      <div class="glossary"> 
        <div class="card-container">
          
          <div class="card">
            <h3>Desinformación</h3>
            <p><em>Información falsa o engañosa difundida con la intención de engañar.</em></p>
          </div>
          
          <div class="card">
            <h3>Moderación de contenido</h3>
            <p><em>Proceso mediante el cual las plataformas digitales revisan y gestionan el contenido publicado para cumplir con sus políticas y normas.</em></p>
          </div>
          
          <div class="card">
            <h3>Viralidad</h3>
            <p><em>Capacidad de un contenido para difundirse rápidamente entre un gran número de personas en internet.</em></p>
          </div>
          
          <div class="card">
            <h3>Meta</h3>
            <p><em>Empresa matriz de Facebook, Instagram y WhatsApp, entre otras plataformas.</em></p>
          </div>
          
        </div>
      </div>
      

      <!-- Opinion terms -->
      
      
      <h2>Opinión pública</h2>
      <ul class="opinion">
        
        <li class="opinion-item">
          <div class="opinion-fuente">David Lazer, profesor de la Universidad Northeastern de Boston</div>
          <p class="opinion-reaccion">Expresó preocupación de que las empresas tecnológicas puedan ignorar el interés público general en favor de ganancias a corto plazo.</p>
        </li>
        
        <li class="opinion-item">
          <div class="opinion-fuente">Sandra González Bailón, profesora de la Universidad de Pensilvania</div>
          <p class="opinion-reaccion">Señaló que una minoría de usuarios es responsable de la mayoría del contenido problemático en las redes sociales.</p>
        </li>
        
      </ul>
      

      <!-- Expected data -->
      
      
      <h2>Datos relevante</h2>
      <div class="data-container">
        <div class="data-content">
          <ul class="data">
            
            <li class="data-item">
              <div class="data-fuente">En julio de 2020, la desinformación etiquetada en Facebook alcanzó 50 millones de visualizaciones, reduciéndose a casi cero en noviembre de ese año.</div>
              <p class="data-reaccion">&mdash; Sociological Science</p>
            </li>
            
            <li class="data-item">
              <div class="data-fuente">Aproximadamente el 1% de los usuarios de Facebook son responsables de la mayoría de la difusión de desinformación en la plataforma.</div>
              <p class="data-reaccion">&mdash; Universidad de Pensilvania</p>
            </li>
            
          </ul>
        </div>
      </div>
      

      <!-- Expected impact -->
      
             
      <h2>Impacto esperado</h2> 
      <p>La revelación de que Facebook puede controlar eficazmente la propagación de desinformación mediante ajustes en sus políticas de moderación podría presionar a la empresa a implementar medidas más estrictas en el futuro. Además, podría influir en otras plataformas para adoptar prácticas similares, fortaleciendo la integridad informativa en entornos digitales.</p>
      

      <!-- Camparations -->
      
             
      <h2>Comparativas</h2> 
      <p>En 2019, WhatsApp limitó la cantidad de veces que un mensaje podía ser reenviado para frenar la difusión de bulos, especialmente en países como India, donde la desinformación había provocado incidentes violentos. Esta medida resultó en una disminución significativa de la propagación de mensajes virales.</p>
      
    </div>

    <!-- Data checked -->
    
    <div class="data-checked-container">
      <h2>Checkeo de datos</h2>
      <ul class="data-checked">
        
        <li class="data-checked-item">
          <div class="data-checked-afirmacion">&raquo; Facebook redujo a casi cero las visualizaciones de desinformación durante las elecciones de EE. UU. en 2020.</div>
          <div class="data-checked-conclusion">
            <span>Confirmado</span>
            <p>El estudio publicado en Sociological Science indica que las visualizaciones de desinformación etiquetada disminuyeron drásticamente en ese período.</p>
          </div>
        </li>
        
        <li class="data-checked-item">
          <div class="data-checked-afirmacion">&raquo; En 2024, Facebook no implementó medidas similares para controlar la desinformación.</div>
          <div class="data-checked-conclusion">
            <span>Confirmado</span>
            <p>Según declaraciones de Nick Clegg, la empresa optó por no aplicar restricciones tan estrictas en 2024.</p>
          </div>
        </li>
        
      </ul>
    </div>
    

    <!-- Reflexion -->
    
    <div class="reflexion">
      <h2>Reflexión breve</h2>
      <p><img id="avatar" src="https://api.dicebear.com/9.x/notionists/svg?seed=random287&size=60&&body=variant22" /> La capacidad de las plataformas digitales para controlar la difusión de desinformación es evidente. Sin embargo, su aplicación depende de decisiones corporativas que deben equilibrar la libertad de expresión con la responsabilidad de mantener un entorno informativo saludable. Es esencial que estas empresas actúen con transparencia y en beneficio del interés público.</p>
    </div>
    

    <!-- footer -->
    <div class="footer">
      <div class="source">
        <p>¿Te ha intrigado este contexto? Sumérgete en la <a href="https://elpais.com/tecnologia/2024-12-12/un-estudio-revela-que-facebook-podria-tumbar-el-impacto-viral-de-los-bulos.html" target="_blank">noticia completa</a> para descubrir todos los detalles.</p>
      </div>
    </div>
    <div class="sign">
      <p>EITB Noticias es un proyecto personal, creado con pasión por la tecnología y las ganas de aprender, cuyo nombre hace referencia a 'Essential Information, Truly Balanced' y no tiene ninguna relación con el portal oficial eitb.eus. Si quieres más información, visita <a href="https://hitzur.com" target="_blank">Hïtzur</a><br /><br /><i>Gogoz ikasi, bihotzez egin</i></p>
    </div>
  </div>
</body>
</html>
